{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replication of electricity price forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days of the week/ Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T16:48:19.391053Z",
     "start_time": "2020-11-25T16:48:16.910232Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform_to_windows\n",
    "converts the data from row data into windowed rows where each row is a day with 24 columns representing each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T17:00:33.899335Z",
     "start_time": "2020-11-25T17:00:33.894298Z"
    }
   },
   "outputs": [],
   "source": [
    "from electricity_price_predictor.data import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T17:00:41.215298Z",
     "start_time": "2020-11-25T17:00:35.653210Z"
    }
   },
   "outputs": [],
   "source": [
    "data = fetch_data('../raw_data/price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T17:00:45.323635Z",
     "start_time": "2020-11-25T17:00:45.314108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time     datetime64[ns]\n",
       "price            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T16:07:09.576787Z",
     "start_time": "2020-11-25T16:07:09.498645Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../raw_data/final_load.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T17:00:48.773912Z",
     "start_time": "2020-11-25T17:00:48.754347Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T17:00:49.832284Z",
     "start_time": "2020-11-25T17:00:49.814241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015,\n",
       "            ...\n",
       "            2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020],\n",
       "           dtype='int64', name='time', length=51702)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T16:00:35.447260Z",
     "start_time": "2020-11-25T16:00:35.322086Z"
    }
   },
   "outputs": [],
   "source": [
    "# load = get_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T16:04:33.222649Z",
     "start_time": "2020-11-25T16:04:33.203061Z"
    }
   },
   "outputs": [],
   "source": [
    "# load.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T16:48:37.389944Z",
     "start_time": "2020-11-25T16:48:37.372439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>25.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>18.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>16.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     price\n",
       "time                      \n",
       "2015-01-01 00:00:00  25.02\n",
       "2015-01-01 01:00:00  18.29\n",
       "2015-01-01 02:00:00  16.04\n",
       "2015-01-01 03:00:00   14.6\n",
       "2015-01-01 04:00:00  14.95"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T17:20:07.136060Z",
     "start_time": "2020-11-25T17:20:07.117096Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_to_windows(data, load_type='actual_load'):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    \n",
    "    Output\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #from the original datetime index create new columns with each of the year, month, day, and hour.\n",
    "    data['year'] = data.index.year\n",
    "    data['month'] = data.index.month\n",
    "    data['day'] = data.index.day\n",
    "    data['hours'] = data.index.hour\n",
    "    \n",
    "    #construct datetimes from the split year, month, day columns\n",
    "    data.loc[:,'date'] = pd.to_datetime(data.loc[:,['year', 'month', 'day']], format='%Y-%m-%d', errors='ignore')\n",
    "    \n",
    "    #set the index to dates only\n",
    "    data = data.set_index(pd.DatetimeIndex(data['date']))\n",
    "    \n",
    "    #drop non target columns \n",
    "#     data = data[:,[load_type, 'hours']]\n",
    "    \n",
    "    #pivot the table into the format Date h0, h1, ...h23\n",
    "    data = data.pivot(columns='hours', values=load_type)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T17:20:08.921625Z",
     "start_time": "2020-11-25T17:20:08.782058Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'actual_load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\gesi\\.venvs\\energy_price\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'actual_load'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c83c25c9908e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtransform_to_windows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-22394ebafd3f>\u001b[0m in \u001b[0;36mtransform_to_windows\u001b[1;34m(data, load_type)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#pivot the table into the format Date h0, h1, ...h23\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hours'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gesi\\.venvs\\energy_price\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(self, index, columns, values)\u001b[0m\n\u001b[0;32m   6676\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6680\u001b[0m     _shared_docs[\n",
      "\u001b[1;32mc:\\users\\gesi\\.venvs\\energy_price\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(data, index, columns, values)\u001b[0m\n\u001b[0;32m    474\u001b[0m             )\n\u001b[0;32m    475\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mindexed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gesi\\.venvs\\energy_price\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gesi\\.venvs\\energy_price\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'actual_load'"
     ]
    }
   ],
   "source": [
    "transform_to_windows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_persistence_dataset(path='./data/cleaned_data/energy_loads_2015_2019.csv', index='time', start='2015', stop='2018', shift=0):\n",
    "#     #load the preprocessed data\n",
    "#     data = pd.read_csv('./data/cleaned_data/energy_loads_2015_2019.csv', parse_dates=True, index_col=index)\n",
    "\n",
    "#     #use features preprocessing library to transform data into day and hour slice format.\n",
    "#     data = transform_to_windows(data)\n",
    "\n",
    "#     #rename the columns\n",
    "#     data = rename_cols(data, shift=shift)\n",
    "\n",
    "#     #standardize the data from 2015-2018\n",
    "#     data = data[start:stop]\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous day hour by hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous day hour by hour model will use the energy loads/price from the previous day to forecast the next days' load/price on an hour by hour basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T15:42:31.308133Z",
     "start_time": "2020-11-25T15:42:31.289513Z"
    }
   },
   "outputs": [],
   "source": [
    "def day_hbh(history, days=1):\n",
    "    \"\"\"\n",
    "    History is a dataframe with index as days, and columns hours in the day. \n",
    "    \n",
    "    \"\"\"\n",
    "    #retrns the last week in the history data set as the forecast for the next week.\n",
    "    return history.iloc[-days,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T14:25:34.525493Z",
     "start_time": "2020-11-25T14:25:34.508666Z"
    }
   },
   "outputs": [],
   "source": [
    "from electricity_price_predictor.data_2 import get_shifted_price, get_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T14:32:36.950798Z",
     "start_time": "2020-11-25T14:32:31.622628Z"
    }
   },
   "outputs": [],
   "source": [
    "prices = get_shifted_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T14:32:37.075558Z",
     "start_time": "2020-11-25T14:32:37.016854Z"
    }
   },
   "outputs": [],
   "source": [
    "load = get_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T09:43:41.075845Z",
     "start_time": "2020-11-25T09:43:41.054843Z"
    }
   },
   "outputs": [],
   "source": [
    "correlations = df.corr(method='pearson')\n",
    "print(correlations['Day-ahead Price [EUR/MWh]'].sort_values(ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T09:47:33.106260Z",
     "start_time": "2020-11-25T09:47:32.704677Z"
    }
   },
   "outputs": [],
   "source": [
    "correlations = df.corr(method='pearson')\n",
    "fig = plt.figure(figsize=(24, 24))\n",
    "sns.heatmap(correlations, annot=True, fmt='.2f')\n",
    "plt.title('Pearson Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T09:34:39.329841Z",
     "start_time": "2020-11-25T09:34:39.051183Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot autocorrelation and partial autocorrelation plots\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(10, 6))\n",
    "plot_acf(df['price actual'], lags=50, ax=ax1)\n",
    "plot_pacf(df['price actual'], lags=50, ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start='1/1/2018', end='31/12/2018')\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T16:05:32.493316Z",
     "start_time": "2020-11-24T16:05:32.323980Z"
    }
   },
   "outputs": [],
   "source": [
    "dates.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain_holidays = holidays.CountryHoliday('ES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain_holidays.get('2018-12-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_holidays(start='1/1/2018', stop='31/12/2018', country='ES', frequency='H'):\n",
    "    \"\"\"\n",
    "    Takes in a start and stop date and a country.\n",
    "    \n",
    "    Produces a dataframe with a daily date time index and columns:\n",
    "    day_of_week - numerical day of the week identifier 0 for monday\n",
    "    holiday_bool - boolean true or false for holiday\n",
    "    holiday_name - name of the holiday if holiday_bool is true\n",
    "    \n",
    "    Returns a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    #generate the range of daily dates\n",
    "    dates = pd.date_range(start=start, end=stop, freq=frequency)\n",
    "    \n",
    "    #create the holiday object\n",
    "    country_holidays = holidays.CountryHoliday(country)\n",
    "\n",
    "    #create a list for the holiday bool and name\n",
    "    holiday_list = []\n",
    "    \n",
    "    #loop through the dates\n",
    "    for date in dates:\n",
    "        #true if holiday in object, false otherwise\n",
    "        holiday_bool = date in country_holidays\n",
    "        holiday_names = country_holidays.get(date)\n",
    "        \n",
    "        holiday_list.append([holiday_bool, holiday_names])\n",
    "        \n",
    "    #create return dataframe\n",
    "    holidays_data = pd.DataFrame(holiday_list, index=dates, columns=['holiday_bool', 'holiday_name'])\n",
    "                  \n",
    "    return holidays_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_days_dummies(start='1/1/2018', stop='31/12/2018', frequency='H'):\n",
    "    \"\"\"\n",
    "    Takes in a start and stop date and frequency.\n",
    "    \n",
    "    Produces a dataframe with a date time index at the frequency input and columns:\n",
    "    weekday_id - numerical day of the week identifier 0 for monday\n",
    "    \n",
    "    Returns a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    #generate the range of daily dates\n",
    "    dates = pd.date_range(start=start, end=stop, freq=frequency)\n",
    "    \n",
    "    #create a dataframe of weekday categories\n",
    "    days = pd.DataFrame(list(dates.weekday), index=dates, columns=['weekday_id'])\n",
    "    \n",
    "    days = pd.get_dummies(days['weekday_id'])\n",
    "    \n",
    "    columns = ['mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun']\n",
    "    \n",
    "    days.columns = columns\n",
    "    \n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the electricity price time series\n",
    "\n",
    "res = sm.tsa.seasonal_decompose(df_energy['price actual'], model='additive')\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(20, 12))\n",
    "res.observed.plot(ax=ax1, title='Observed')\n",
    "res.trend.plot(ax=ax2, title='Trend')\n",
    "res.resid.plot(ax=ax3, title='Residual')\n",
    "res.seasonal.plot(ax=ax4, title='Seasonal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the log electricity price time-series\n",
    "\n",
    "res = sm.tsa.seasonal_decompose(np.log(df_energy['price actual']), model='additive')\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(20, 12))\n",
    "res.observed.plot(ax=ax1, title='Observed')\n",
    "res.trend.plot(ax=ax2, title='Trend')\n",
    "res.resid.plot(ax=ax3, title='Residual')\n",
    "res.seasonal.plot(ax=ax4, title='Seasonal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation, partial autocorrelation and cross-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot autocorrelation and partial autocorrelation plots\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(10, 6))\n",
    "plot_acf(df_final['price actual'], lags=50, ax=ax1)\n",
    "plot_pacf(df_final['price actual'], lags=50, ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlations between the electricity price and the rest of the features\n",
    "\n",
    "correlations = df_final.corr(method='pearson')\n",
    "print(correlations['price actual'].sort_values(ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Pearson correlation matrix\n",
    "\n",
    "correlations = df_final.corr(method='pearson')\n",
    "fig = plt.figure(figsize=(24, 24))\n",
    "sns.heatmap(correlations, annot=True, fmt='.2f')\n",
    "plt.title('Pearson Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_correlated = abs(correlations[correlations > 0.75])\n",
    "print(highly_correlated[highly_correlated < 1.0].stack().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'hour', 'weekday' and 'month' features\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    position = df_final.index[i]\n",
    "    hour = position.hour\n",
    "    weekday = position.weekday()\n",
    "    month = position.month\n",
    "    df_final.loc[position, 'hour'] = hour\n",
    "    df_final.loc[position, 'weekday'] = weekday\n",
    "    df_final.loc[position, 'month'] = month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'business hour' feature\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    position = df_final.index[i]\n",
    "    hour = position.hour\n",
    "    if ((hour > 8 and hour < 14) or (hour > 16 and hour < 21)):\n",
    "        df_final.loc[position, 'business hour'] = 2\n",
    "    elif (hour >= 14 and hour <= 16):\n",
    "        df_final.loc[position, 'business hour'] = 1\n",
    "    else:\n",
    "        df_final.loc[position, 'business hour'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'weekend' feature\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    position = df_final.index[i]\n",
    "    weekday = position.weekday()\n",
    "    if (weekday == 6):\n",
    "        df_final.loc[position, 'weekday'] = 2\n",
    "    elif (weekday == 5):\n",
    "        df_final.loc[position, 'weekday'] = 1\n",
    "    else:\n",
    "        df_final.loc[position, 'weekday'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'temp_range' for each city\n",
    "\n",
    "cities = ['Barcelona', 'Bilbao', 'Madrid', 'Seville', 'Valencia']\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    position = df_final.index[i]\n",
    "    for city in cities:\n",
    "        temp_max = df_final.loc[position, 'temp_max_{}'.format(city)]\n",
    "        temp_min = df_final.loc[position, 'temp_min_{}'.format(city)]\n",
    "        df_final.loc[position, 'temp_range_{}'.format(city)] = abs(temp_max - temp_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weight of every city\n",
    "\n",
    "total_pop = 6155116 + 5179243 + 1645342 + 1305342 + 987000\n",
    "\n",
    "weight_Madrid = 6155116 / total_pop\n",
    "weight_Barcelona = 5179243 / total_pop\n",
    "weight_Valencia = 1645342 / total_pop\n",
    "weight_Seville = 1305342 / total_pop\n",
    "weight_Bilbao = 987000 / total_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_weights = {'Madrid': weight_Madrid, \n",
    "                  'Barcelona': weight_Barcelona,\n",
    "                  'Valencia': weight_Valencia,\n",
    "                  'Seville': weight_Seville,\n",
    "                  'Bilbao': weight_Bilbao}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'temp_weighted' feature\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    position = df_final.index[i]\n",
    "    temp_weighted = 0\n",
    "    for city in cities:\n",
    "        temp = df_final.loc[position, 'temp_{}'.format(city)]\n",
    "        temp_weighted += temp * cities_weights.get('{}'.format(city))\n",
    "    df_final.loc[position, 'temp_weighted'] = temp_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electricity price forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T16:07:47.789232Z",
     "start_time": "2020-11-24T16:07:47.784230Z"
    }
   },
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "%matplotlib inline\n",
    "sns.set_style('dark')\n",
    "\n",
    "#import libraries for statistical analysis\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARIMAResults\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX, SARIMAXResults\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "#import libraries for parallel processing\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "\n",
    "#import custom utils including persistence testbench\n",
    "from model_persistence import get_persistence_dataset, train_test_split, walk_forward_evaluation, calculate_errors, plot_error\n",
    "from create_day_types import get_days_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset and crete the train and test sets.\n",
    "data = get_persistence_dataset(transformed=True)\n",
    "\n",
    "#split using default date 2017-12-31\n",
    "train, test = train_test_split(data)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.index.min(), train.index.max(),test.index.min(), test.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the train set because the statistical model only accepts univariate series\n",
    "train_flat = train.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationery test over 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(adful_t[0:4], index=['Test Statistic','p-value','#Lags','Observations']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationery teset over 1 week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T16:09:39.260845Z",
     "start_time": "2020-11-24T16:09:39.242003Z"
    }
   },
   "outputs": [],
   "source": [
    "adful_t = sm.tsa.adfuller(train_flat, maxlag=24*30)\n",
    "print(pd.Series(adful_t[0:4], index=['Test Statistic','p-value','#Lags','Observations']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation and partial autocoreelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the ACF \n",
    "fig, axs = plt.subplots(2,2, figsize=(10,10))\n",
    "\n",
    "lags = [48, 24*7, 24*14, 24*365]\n",
    "\n",
    "for lag, ax in zip(lags, axs.flatten()):\n",
    "    plot_acf(train_flat, lags=lag, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the ACF \n",
    "fig, axs = plt.subplots(2,2, figsize=(10,10))\n",
    "\n",
    "lags = [24, 24*3, 24*7, 24*14]\n",
    "\n",
    "for lag, ax in zip(lags, axs.flatten()):\n",
    "    plot_pacf(train_flat, lags=lag, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA Model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the model for one forecasting period and estimate how long it will take to implement\n",
    "\n",
    "def test_run_ARIMA(train_flat):\n",
    "    #setup a model instence\n",
    "    model_24 = ARIMA(train_flat, order=(24, 0, 0))\n",
    "\n",
    "    #fit the model\n",
    "    model_fit_24 = model_24.fit()\n",
    "\n",
    "    #run the 24 interval forecast and return the operation time\n",
    "    forecast_24, std_24, intervals_24 = model_fit_24.forecast(24)\n",
    "    \n",
    "    return forecast_24, std_24, intervals_24\n",
    "    \n",
    "%time forecast_24, std_24, intervals_24 = test_run_ARIMA(train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the result and get an idea if the forecast is in the right direction\n",
    "fig = plt.figure(figsize=(8,7))\n",
    "\n",
    "plt.plot(forecast_24, label='Predicted day')\n",
    "plt.plot(intervals_24[:,0], label='High/Low confidence interval', color='gray')\n",
    "plt.plot(intervals_24[:,1], color='gray')\n",
    "plt.plot(test.iloc[0,:], label='Actual day')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('ARIMA Forecast vs. Actual for first day in test set')\n",
    "plt.xlabel('MWh')\n",
    "plt.ylabel('Hour of Day')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the root mean squared error of the single test run\n",
    "print('ARIMA 1 step walk forward RMSE: {0:.2f} MWh' .format(mean_absolute_error(test.iloc[0,:], forecast_24)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a model to insert into the training rig created in the persistence workbook\n",
    "def arima_model(history, config):\n",
    "    \n",
    "    #convert dataframe to numpy array and flatten into column vector\n",
    "    history_flat = history.values.flatten()\n",
    "    \n",
    "    p,d,q = config\n",
    "    \n",
    "    #initalize the ARIMA model\n",
    "    model = ARIMA(history_flat, order=(p, d, q))\n",
    "    \n",
    "    #fit model\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    #generate forecast for the next 24 hours\n",
    "    forecast, _, _ = model_fit.forecast(24)\n",
    "    \n",
    "    #save the model\n",
    "    #name = 'model-' + str(datetime.datetime.now()) +'.pkl'\n",
    "    #model_fit.save(name)\n",
    "    \n",
    "    #print('Done. Model Saved.')\n",
    "    \n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, errors_mean, prediction = walk_forward_evaluation(arima_model, train, test, 'arima_model', config=(1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error(errors, result_set=['arima_model'], title='Baseline ARIMA model errors (1,0,0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_rmse_and_loss(history):\n",
    "    \n",
    "    # Evaluate train and validation accuracies and losses\n",
    "    \n",
    "    train_rmse = history.history['root_mean_squared_error']\n",
    "    val_rmse = history.history['val_root_mean_squared_error']\n",
    "    \n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    # Visualize epochs vs. train and validation accuracies and losses\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_rmse, label='Training RMSE')\n",
    "    plt.plot(val_rmse, label='Validation RMSE')\n",
    "    plt.legend()\n",
    "    plt.title('Epochs vs. Training and Validation RMSE')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Epochs vs. Training and Validation Loss')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "multivariate_lstm = tf.keras.models.Sequential([\n",
    "    LSTM(100, input_shape=input_shape, \n",
    "         return_sequences=True),\n",
    "    Flatten(),\n",
    "    Dense(200, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                   'multivariate_lstm.h5', monitor=('val_loss'), save_best_only=True)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=6e-3, amsgrad=True)\n",
    "\n",
    "multivariate_lstm.compile(loss=loss,\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = multivariate_lstm.fit(train, epochs=120,\n",
    "                                validation_data=validation,\n",
    "                                callbacks=[early_stopping, \n",
    "                                           model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_rmse_and_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_lstm = tf.keras.models.load_model('multivariate_lstm.h5')\n",
    "\n",
    "forecast = multivariate_lstm.predict(X_test)\n",
    "lstm_forecast = scaler_y.inverse_transform(forecast)\n",
    "\n",
    "rmse_lstm = sqrt(mean_squared_error(y_test_inv,\n",
    "                                    lstm_forecast))\n",
    "print('RMSE of hour-ahead electricity price LSTM forecast: {}'\n",
    "      .format(round(rmse_lstm, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "multivariate_stacked_lstm = tf.keras.models.Sequential([\n",
    "    LSTM(250, input_shape=input_shape, \n",
    "         return_sequences=True),\n",
    "    LSTM(150, return_sequences=True),\n",
    "    Flatten(),\n",
    "    Dense(150, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                   'multivariate_stacked_lstm.h5', save_best_only=True)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=3e-3, amsgrad=True)\n",
    "\n",
    "multivariate_stacked_lstm.compile(loss=loss,\n",
    "                                  optimizer=optimizer,\n",
    "                                  metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = multivariate_stacked_lstm.fit(train, epochs=120,\n",
    "                                validation_data=validation,\n",
    "                                callbacks=[early_stopping, \n",
    "                                           model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_rmse_and_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_stacked_lstm = tf.keras.models.load_model('multivariate_stacked_lstm.h5')\n",
    "\n",
    "forecast = multivariate_stacked_lstm.predict(X_test)\n",
    "multivariate_stacked_lstm_forecast = scaler_y.inverse_transform(forecast)\n",
    "\n",
    "rmse_mult_stacked_lstm = sqrt(mean_squared_error(y_test_inv, \n",
    "                                                 multivariate_stacked_lstm_forecast))\n",
    "print('RMSE of hour-ahead electricity price multivariate Stacked LSTM forecast: {}'\n",
    "      .format(round(rmse_mult_stacked_lstm, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
