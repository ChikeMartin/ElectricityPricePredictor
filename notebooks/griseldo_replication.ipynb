{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replication of electricity price forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days of the week/ Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start='1/1/2018', end='31/12/2018')\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T16:05:32.493316Z",
     "start_time": "2020-11-24T16:05:32.323980Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9470049855bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweekday\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dates' is not defined"
     ]
    }
   ],
   "source": [
    "dates.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain_holidays = holidays.CountryHoliday('ES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain_holidays.get('2018-12-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_holidays(start='1/1/2018', stop='31/12/2018', country='ES', frequency='H'):\n",
    "    \"\"\"\n",
    "    Takes in a start and stop date and a country.\n",
    "    \n",
    "    Produces a dataframe with a daily date time index and columns:\n",
    "    day_of_week - numerical day of the week identifier 0 for monday\n",
    "    holiday_bool - boolean true or false for holiday\n",
    "    holiday_name - name of the holiday if holiday_bool is true\n",
    "    \n",
    "    Returns a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    #generate the range of daily dates\n",
    "    dates = pd.date_range(start=start, end=stop, freq=frequency)\n",
    "    \n",
    "    #create the holiday object\n",
    "    country_holidays = holidays.CountryHoliday(country)\n",
    "\n",
    "    #create a list for the holiday bool and name\n",
    "    holiday_list = []\n",
    "    \n",
    "    #loop through the dates\n",
    "    for date in dates:\n",
    "        #true if holiday in object, false otherwise\n",
    "        holiday_bool = date in country_holidays\n",
    "        holiday_names = country_holidays.get(date)\n",
    "        \n",
    "        holiday_list.append([holiday_bool, holiday_names])\n",
    "        \n",
    "    #create return dataframe\n",
    "    holidays_data = pd.DataFrame(holiday_list, index=dates, columns=['holiday_bool', 'holiday_name'])\n",
    "                  \n",
    "    return holidays_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_days_dummies(start='1/1/2018', stop='31/12/2018', frequency='H'):\n",
    "    \"\"\"\n",
    "    Takes in a start and stop date and frequency.\n",
    "    \n",
    "    Produces a dataframe with a date time index at the frequency input and columns:\n",
    "    weekday_id - numerical day of the week identifier 0 for monday\n",
    "    \n",
    "    Returns a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    #generate the range of daily dates\n",
    "    dates = pd.date_range(start=start, end=stop, freq=frequency)\n",
    "    \n",
    "    #create a dataframe of weekday categories\n",
    "    days = pd.DataFrame(list(dates.weekday), index=dates, columns=['weekday_id'])\n",
    "    \n",
    "    days = pd.get_dummies(days['weekday_id'])\n",
    "    \n",
    "    columns = ['mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun']\n",
    "    \n",
    "    days.columns = columns\n",
    "    \n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the electricity price time series\n",
    "\n",
    "res = sm.tsa.seasonal_decompose(df_energy['price actual'], model='additive')\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(20, 12))\n",
    "res.observed.plot(ax=ax1, title='Observed')\n",
    "res.trend.plot(ax=ax2, title='Trend')\n",
    "res.resid.plot(ax=ax3, title='Residual')\n",
    "res.seasonal.plot(ax=ax4, title='Seasonal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the log electricity price time-series\n",
    "\n",
    "res = sm.tsa.seasonal_decompose(np.log(df_energy['price actual']), model='additive')\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(20, 12))\n",
    "res.observed.plot(ax=ax1, title='Observed')\n",
    "res.trend.plot(ax=ax2, title='Trend')\n",
    "res.resid.plot(ax=ax3, title='Residual')\n",
    "res.seasonal.plot(ax=ax4, title='Seasonal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation, partial autocorrelation and cross-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot autocorrelation and partial autocorrelation plots\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(10, 6))\n",
    "plot_acf(df_final['price actual'], lags=50, ax=ax1)\n",
    "plot_pacf(df_final['price actual'], lags=50, ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlations between the electricity price and the rest of the features\n",
    "\n",
    "correlations = df_final.corr(method='pearson')\n",
    "print(correlations['price actual'].sort_values(ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Pearson correlation matrix\n",
    "\n",
    "correlations = df_final.corr(method='pearson')\n",
    "fig = plt.figure(figsize=(24, 24))\n",
    "sns.heatmap(correlations, annot=True, fmt='.2f')\n",
    "plt.title('Pearson Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_correlated = abs(correlations[correlations > 0.75])\n",
    "print(highly_correlated[highly_correlated < 1.0].stack().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'hour', 'weekday' and 'month' features\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    position = df_final.index[i]\n",
    "    hour = position.hour\n",
    "    weekday = position.weekday()\n",
    "    month = position.month\n",
    "    df_final.loc[position, 'hour'] = hour\n",
    "    df_final.loc[position, 'weekday'] = weekday\n",
    "    df_final.loc[position, 'month'] = month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'business hour' feature\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    position = df_final.index[i]\n",
    "    hour = position.hour\n",
    "    if ((hour > 8 and hour < 14) or (hour > 16 and hour < 21)):\n",
    "        df_final.loc[position, 'business hour'] = 2\n",
    "    elif (hour >= 14 and hour <= 16):\n",
    "        df_final.loc[position, 'business hour'] = 1\n",
    "    else:\n",
    "        df_final.loc[position, 'business hour'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'weekend' feature\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    position = df_final.index[i]\n",
    "    weekday = position.weekday()\n",
    "    if (weekday == 6):\n",
    "        df_final.loc[position, 'weekday'] = 2\n",
    "    elif (weekday == 5):\n",
    "        df_final.loc[position, 'weekday'] = 1\n",
    "    else:\n",
    "        df_final.loc[position, 'weekday'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'temp_range' for each city\n",
    "\n",
    "cities = ['Barcelona', 'Bilbao', 'Madrid', 'Seville', 'Valencia']\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    position = df_final.index[i]\n",
    "    for city in cities:\n",
    "        temp_max = df_final.loc[position, 'temp_max_{}'.format(city)]\n",
    "        temp_min = df_final.loc[position, 'temp_min_{}'.format(city)]\n",
    "        df_final.loc[position, 'temp_range_{}'.format(city)] = abs(temp_max - temp_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weight of every city\n",
    "\n",
    "total_pop = 6155116 + 5179243 + 1645342 + 1305342 + 987000\n",
    "\n",
    "weight_Madrid = 6155116 / total_pop\n",
    "weight_Barcelona = 5179243 / total_pop\n",
    "weight_Valencia = 1645342 / total_pop\n",
    "weight_Seville = 1305342 / total_pop\n",
    "weight_Bilbao = 987000 / total_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_weights = {'Madrid': weight_Madrid, \n",
    "                  'Barcelona': weight_Barcelona,\n",
    "                  'Valencia': weight_Valencia,\n",
    "                  'Seville': weight_Seville,\n",
    "                  'Bilbao': weight_Bilbao}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'temp_weighted' feature\n",
    "\n",
    "for i in range(len(df_final)):\n",
    "    position = df_final.index[i]\n",
    "    temp_weighted = 0\n",
    "    for city in cities:\n",
    "        temp = df_final.loc[position, 'temp_{}'.format(city)]\n",
    "        temp_weighted += temp * cities_weights.get('{}'.format(city))\n",
    "    df_final.loc[position, 'temp_weighted'] = temp_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electricity price forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T16:07:47.789232Z",
     "start_time": "2020-11-24T16:07:47.784230Z"
    }
   },
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "%matplotlib inline\n",
    "sns.set_style('dark')\n",
    "\n",
    "#import libraries for statistical analysis\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARIMAResults\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX, SARIMAXResults\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "#import libraries for parallel processing\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "\n",
    "#import custom utils including persistence testbench\n",
    "from model_persistence import get_persistence_dataset, train_test_split, walk_forward_evaluation, calculate_errors, plot_error\n",
    "from create_day_types import get_days_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset and crete the train and test sets.\n",
    "data = get_persistence_dataset(transformed=True)\n",
    "\n",
    "#split using default date 2017-12-31\n",
    "train, test = train_test_split(data)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.index.min(), train.index.max(),test.index.min(), test.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the train set because the statistical model only accepts univariate series\n",
    "train_flat = train.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationery test over 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(adful_t[0:4], index=['Test Statistic','p-value','#Lags','Observations']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationery teset over 1 week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T16:09:39.260845Z",
     "start_time": "2020-11-24T16:09:39.242003Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f46def2a45b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0madful_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madfuller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madful_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Test Statistic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'p-value'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'#Lags'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Observations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sm' is not defined"
     ]
    }
   ],
   "source": [
    "adful_t = sm.tsa.adfuller(train_flat, maxlag=24*30)\n",
    "print(pd.Series(adful_t[0:4], index=['Test Statistic','p-value','#Lags','Observations']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation and partial autocoreelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the ACF \n",
    "fig, axs = plt.subplots(2,2, figsize=(10,10))\n",
    "\n",
    "lags = [48, 24*7, 24*14, 24*365]\n",
    "\n",
    "for lag, ax in zip(lags, axs.flatten()):\n",
    "    plot_acf(train_flat, lags=lag, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the ACF \n",
    "fig, axs = plt.subplots(2,2, figsize=(10,10))\n",
    "\n",
    "lags = [24, 24*3, 24*7, 24*14]\n",
    "\n",
    "for lag, ax in zip(lags, axs.flatten()):\n",
    "    plot_pacf(train_flat, lags=lag, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA Model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the model for one forecasting period and estimate how long it will take to implement\n",
    "\n",
    "def test_run_ARIMA(train_flat):\n",
    "    #setup a model instence\n",
    "    model_24 = ARIMA(train_flat, order=(24, 0, 0))\n",
    "\n",
    "    #fit the model\n",
    "    model_fit_24 = model_24.fit()\n",
    "\n",
    "    #run the 24 interval forecast and return the operation time\n",
    "    forecast_24, std_24, intervals_24 = model_fit_24.forecast(24)\n",
    "    \n",
    "    return forecast_24, std_24, intervals_24\n",
    "    \n",
    "%time forecast_24, std_24, intervals_24 = test_run_ARIMA(train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the result and get an idea if the forecast is in the right direction\n",
    "fig = plt.figure(figsize=(8,7))\n",
    "\n",
    "plt.plot(forecast_24, label='Predicted day')\n",
    "plt.plot(intervals_24[:,0], label='High/Low confidence interval', color='gray')\n",
    "plt.plot(intervals_24[:,1], color='gray')\n",
    "plt.plot(test.iloc[0,:], label='Actual day')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('ARIMA Forecast vs. Actual for first day in test set')\n",
    "plt.xlabel('MWh')\n",
    "plt.ylabel('Hour of Day')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the root mean squared error of the single test run\n",
    "print('ARIMA 1 step walk forward RMSE: {0:.2f} MWh' .format(mean_absolute_error(test.iloc[0,:], forecast_24)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a model to insert into the training rig created in the persistence workbook\n",
    "def arima_model(history, config):\n",
    "    \n",
    "    #convert dataframe to numpy array and flatten into column vector\n",
    "    history_flat = history.values.flatten()\n",
    "    \n",
    "    p,d,q = config\n",
    "    \n",
    "    #initalize the ARIMA model\n",
    "    model = ARIMA(history_flat, order=(p, d, q))\n",
    "    \n",
    "    #fit model\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    #generate forecast for the next 24 hours\n",
    "    forecast, _, _ = model_fit.forecast(24)\n",
    "    \n",
    "    #save the model\n",
    "    #name = 'model-' + str(datetime.datetime.now()) +'.pkl'\n",
    "    #model_fit.save(name)\n",
    "    \n",
    "    #print('Done. Model Saved.')\n",
    "    \n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, errors_mean, prediction = walk_forward_evaluation(arima_model, train, test, 'arima_model', config=(1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error(errors, result_set=['arima_model'], title='Baseline ARIMA model errors (1,0,0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_rmse_and_loss(history):\n",
    "    \n",
    "    # Evaluate train and validation accuracies and losses\n",
    "    \n",
    "    train_rmse = history.history['root_mean_squared_error']\n",
    "    val_rmse = history.history['val_root_mean_squared_error']\n",
    "    \n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    # Visualize epochs vs. train and validation accuracies and losses\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_rmse, label='Training RMSE')\n",
    "    plt.plot(val_rmse, label='Validation RMSE')\n",
    "    plt.legend()\n",
    "    plt.title('Epochs vs. Training and Validation RMSE')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Epochs vs. Training and Validation Loss')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "multivariate_lstm = tf.keras.models.Sequential([\n",
    "    LSTM(100, input_shape=input_shape, \n",
    "         return_sequences=True),\n",
    "    Flatten(),\n",
    "    Dense(200, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                   'multivariate_lstm.h5', monitor=('val_loss'), save_best_only=True)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=6e-3, amsgrad=True)\n",
    "\n",
    "multivariate_lstm.compile(loss=loss,\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = multivariate_lstm.fit(train, epochs=120,\n",
    "                                validation_data=validation,\n",
    "                                callbacks=[early_stopping, \n",
    "                                           model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_rmse_and_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_lstm = tf.keras.models.load_model('multivariate_lstm.h5')\n",
    "\n",
    "forecast = multivariate_lstm.predict(X_test)\n",
    "lstm_forecast = scaler_y.inverse_transform(forecast)\n",
    "\n",
    "rmse_lstm = sqrt(mean_squared_error(y_test_inv,\n",
    "                                    lstm_forecast))\n",
    "print('RMSE of hour-ahead electricity price LSTM forecast: {}'\n",
    "      .format(round(rmse_lstm, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "multivariate_stacked_lstm = tf.keras.models.Sequential([\n",
    "    LSTM(250, input_shape=input_shape, \n",
    "         return_sequences=True),\n",
    "    LSTM(150, return_sequences=True),\n",
    "    Flatten(),\n",
    "    Dense(150, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                   'multivariate_stacked_lstm.h5', save_best_only=True)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=3e-3, amsgrad=True)\n",
    "\n",
    "multivariate_stacked_lstm.compile(loss=loss,\n",
    "                                  optimizer=optimizer,\n",
    "                                  metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = multivariate_stacked_lstm.fit(train, epochs=120,\n",
    "                                validation_data=validation,\n",
    "                                callbacks=[early_stopping, \n",
    "                                           model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_rmse_and_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_stacked_lstm = tf.keras.models.load_model('multivariate_stacked_lstm.h5')\n",
    "\n",
    "forecast = multivariate_stacked_lstm.predict(X_test)\n",
    "multivariate_stacked_lstm_forecast = scaler_y.inverse_transform(forecast)\n",
    "\n",
    "rmse_mult_stacked_lstm = sqrt(mean_squared_error(y_test_inv, \n",
    "                                                 multivariate_stacked_lstm_forecast))\n",
    "print('RMSE of hour-ahead electricity price multivariate Stacked LSTM forecast: {}'\n",
    "      .format(round(rmse_mult_stacked_lstm, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
